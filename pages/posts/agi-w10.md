---
title: AGI周记 2023第10周
date: 2023/3/6
description: AGI周记 2023第10周
tag: agi, llm
author: You
---

1. 本周最重要的新闻无疑是 ChatGPT API 的正式发布。虽然 ChatGPT Turbo 和 DaVinci 在质量上各有千秋，但仅仅 1/10 的价格和 5 倍的速度，着无意识在成本敏感的场景下的重磅炸弹。
2. 其次是 Facebook 推出的 LLaMA，虽然该模型已在上周发布了代码，但直到本周才开始提供模型的下载链接，而后也有大公无私的人放出了BT种子。
3. 人们开始对LLaMA模型进行测试，获得了一些初步的[结果](https://medium.com/@enryu9000/mini-post-first-look-at-llama-4403517d41a1)，如不错的Few Shot Classification能力。但整体实验结果还是比较少，个人觉得还要再观望一阵子。挺好奇 LLaMA 33B/65B 和同样是这周发布的 Flan-UL2 20B，甚至是 GLM 130B 的对比。好奇 Emergent Abilities 到底会不会在这些相对较小的模型上出现。
4. 个人觉得大模型当前一个重要问题就是新模型的测试和验证上。即使不论算力和成本的问题，如何能覆盖五花八门且与日俱增的任务，并且让验证结果不仅仅是个数，还能够辅助最终应用测的效果评估，这都是难题。
6. 以LLM应用构建者的身份看，假设今天又出现了一个自称的GPT竞品，我至少会好奇
	1. 它直接应用在在各类数据集上的效果，当个基础
	2. 它应用各类Trick后的最好结果，比如Chain of Thought, Few Shot Learning，Retrieval Assistance, ToolFormer。对于应用构建者来说，这个是更务实的，用于回答「这个模型能不能用」的指标。
	3. 它与旧有的模型的相似性，比如它的「文风」是否与旧有模型相似，比如它出错的场景是否与旧有模型相似，以便确认要改变哪些prompt和解析程序，同时控制用户体验的变化。
6. 无独有偶，今天Greg Brockman 发布了一条推文，指出在机器学习中最被忽视的技能是创建评估标准。
7. 今天最接近这个目标的应该还是BigBench，它的任务很多样，且允许定义脚本化的、复杂的、多轮验证规则，但据我了解，它对上面提到的各类Trick的效果的验证还比较少。
8. 希望我们很快就能在每一个模型发布时都能快速且全面的完成模型的比对，和选型切换。
